{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5cd3f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'C:/Users/ROG/OneDrive/桌面/FYP/Dataset/Train_data/train_data_after_washing.csv'\n",
    "test_dir = 'C:/Users/ROG/OneDrive/桌面/FYP/Dataset/Test_data/test_data_after_washing.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719cb7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score, cohen_kappa_score, roc_curve, auc, make_scorer, accuracy_score, f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bbc9a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(train_dir)\n",
    "data = pd.DataFrame(data)\n",
    "test_data = pd.read_csv(test_dir)\n",
    "test_data = pd.DataFrame(test_data)\n",
    "train_data = pd.DataFrame()\n",
    "val_data = pd.DataFrame()\n",
    "data = data[[\"review\",\"rating\"]]\n",
    "test_data = test_data[[\"review\",\"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83fa74bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['labels'] = data['rating'].map({1 : 0,\n",
    "                                     2 : 0,\n",
    "                                     3 : 0,\n",
    "                                     4 : 0,\n",
    "                                     5 : 1,\n",
    "                                     6 : 1,\n",
    "                                     7 : 1,\n",
    "                                     8 : 1,\n",
    "                                     9 : 2,\n",
    "                                     10 : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf131fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['labels'] = test_data['rating'].map({1 : 0,\n",
    "                                               2 : 0,\n",
    "                                               3 : 0,\n",
    "                                               4 : 0,\n",
    "                                               5 : 1,\n",
    "                                               6 : 1,\n",
    "                                               7 : 1,\n",
    "                                               8 : 1,\n",
    "                                               9 : 2,\n",
    "                                               10 : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d637a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"review\",\"labels\"]]\n",
    "test_data = test_data[[\"review\",\"labels\"]]\n",
    "y = data[\"labels\"].to_numpy()\n",
    "Y = data[\"labels\"]\n",
    "X = data[\"review\"].to_numpy()\n",
    "test_X = test_data[\"review\"].to_numpy()\n",
    "test_y = test_data[\"labels\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "913b9e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"C:/Users/ROG/OneDrive/桌面/FYP/Model/Mental/\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"C:/Users/ROG/OneDrive/桌面/FYP/Model/Mental/\", num_labels=3) # 2 labels for positive and negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab9661af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(\"./Mental/\")\n",
    "model.save_pretrained(\"./Mental/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c82c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graded_precision(y_true, y_pred, weights):\n",
    "    precision_0 = precision_score(y_true, y_pred, labels=[0], average='macro')\n",
    "    precision_1 = precision_score(y_true, y_pred, labels=[1], average='macro')\n",
    "    precision_2 = precision_score(y_true, y_pred, labels=[2], average='macro')\n",
    "    gp = ( weights[0] * precision_0 + weights[1] * precision_1 + weights[2] * precision_2 ) / ( weights[0] + weights[1] + weights[2] )\n",
    "    return gp\n",
    "def graded_recall(y_true, y_pred, weights):\n",
    "    recall_0 = recall_score(y_true, y_pred, labels=[0], average='macro')\n",
    "    recall_1 = recall_score(y_true, y_pred, labels=[1], average='macro')\n",
    "    recall_2 = recall_score(y_true, y_pred, labels=[2], average='macro')\n",
    "    gr = ( weights[0] * recall_0 + weights[1] * recall_1 + weights[2] * recall_2 ) / ( weights[0] + weights[1] + weights[2] )\n",
    "    return gr\n",
    "def graded_f1(precision, recall):\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e95767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CM(y_true, y_pre, times):\n",
    "        times = str(times)\n",
    "        con_mat = confusion_matrix(y, pred)\n",
    "        con_mat_norm = con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis]     # 归一化\n",
    "        con_mat_norm = np.around(con_mat_norm, decimals=2)\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(con_mat_norm, annot=True, cmap='Blues')\n",
    "        plt.ylim(0, 3)\n",
    "        plt.xlabel('Predicted labels')\n",
    "        plt.ylabel('True labels')\n",
    "        #save CM\n",
    "        plt.savefig(fname='C:/Users/ROG/OneDrive/桌面/FYP/Model/Mental/'+ times + '/CM.png', dpi=300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b2a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10)\n",
    "val_acc = []\n",
    "val_gp = []\n",
    "val_gr = []\n",
    "val_f1 = []\n",
    "val_kp = []\n",
    "tes_acc = []\n",
    "tes_gp = []\n",
    "tes_gr = []\n",
    "tes_f1 = []\n",
    "tes_kp = []\n",
    "train_time = []\n",
    "times = 0\n",
    "for train_index, val_index in skf.split(X, y):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = Y[train_index], Y[val_index]\n",
    "    \n",
    "    X_train = X_train.astype(str).tolist()\n",
    "    y_train = y_train.astype(int).tolist()\n",
    "    X_val = X_val.astype(str).tolist()\n",
    "    y_val = y_val.astype(int).tolist()\n",
    "    test_X = test_X.astype(str).tolist()\n",
    "    test_y = test_y.astype(int).tolist()\n",
    "    \n",
    "    #Create train set, validation set and test set\n",
    "    inputs = tokenizer(X_train, padding=True, max_length=512, truncation=True, return_tensors=\"pt\") # tokenize texts\n",
    "    train_dataset = TensorDataset(inputs[\"input_ids\"], inputs[\"attention_mask\"], torch.tensor(y_train)) # create dataset\n",
    "    inputs = tokenizer(X_val, padding=True, max_length=512, truncation=True, return_tensors=\"pt\") # tokenize texts\n",
    "    val_dataset = TensorDataset(inputs[\"input_ids\"], inputs[\"attention_mask\"], torch.tensor(y_val)) # create dataset\n",
    "    inputs = tokenizer(test_X, padding=True,  max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "    test_dataset = TensorDataset(inputs[\"input_ids\"], inputs[\"attention_mask\"], torch.tensor(test_y)) # create dataset\n",
    "    \n",
    "    #Create data loader \n",
    "    batch_size = 12 # sample batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) # train data loader\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size) # validation data loader\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size) # test data loader \n",
    "    \n",
    "    # Train model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # use GPU if available\n",
    "    model.to(device) # move model to device\n",
    "    criterion = nn.CrossEntropyLoss() # loss function\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-5) # optimizer\n",
    "    epochs = 150 # sample number of epochs\n",
    "    t0 = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm(train_loader, total=len(train_loader))\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        model.train() # set model to train mode\n",
    "        train_loss = 0.0 # initialize train loss\n",
    "        for batch in pbar:\n",
    "            input_ids, attention_mask, labels = batch # get batch data\n",
    "            input_ids = input_ids.to(device) # move input ids to device\n",
    "            attention_mask = attention_mask.to(device) # move attention mask to device\n",
    "            labels = labels.to(device) # move labels to device\n",
    "            optimizer.zero_grad() # zero the gradients\n",
    "            outputs = model(input_ids, attention_mask=attention_mask) # forward pass\n",
    "            loss = criterion(outputs.logits, labels) # compute loss\n",
    "            loss.backward() # backward pass\n",
    "            optimizer.step() # update parameters\n",
    "            train_loss += loss.item() # accumulate train loss\n",
    "            #pbar.set_description(f\"Epoch {epoch+1}\")\n",
    "        \n",
    "        print(f\"Train loss: {train_loss/len(train_loader)}\") # print average train loss\n",
    "    t1 = time.time()\n",
    "    time_train = t1 - t0\n",
    "    train_time.append(time_train)\n",
    "    directory = 'C:/Users/ROG/OneDrive/桌面/FYP/Model/Mental/'+ str(times)\n",
    "    os.makedirs (directory, exist_ok=True)\n",
    "    torch.save(model.state_dict(), directory + '/model_weights.pth')\n",
    "    \n",
    "    #Valitdate model\n",
    "    model.eval() # set model to eval mode\n",
    "    val_loss = 0.0 # initialize test loss\n",
    "    with torch.no_grad(): # no gradient computation\n",
    "        for batch in val_loader:\n",
    "            input_ids, attention_mask, labels = batch # get batch data\n",
    "            input_ids = input_ids.to(device) # move input ids to device\n",
    "            attention_mask = attention_mask.to(device) # move attention mask to device\n",
    "            labels = labels.to(device) # move labels to device\n",
    "            outputs = model(input_ids, attention_mask=attention_mask) # forward pass\n",
    "            loss = criterion(outputs.logits, labels) # compute loss\n",
    "            preds = torch.argmax(outputs.logits, dim=1) # get predictions\n",
    "            test_loss += loss.item() # accumulate test loss \n",
    "            test_preds.extend(preds.cpu().tolist()) # store test predictions \n",
    "            test_labels.extend(labels.cpu().tolist()) # store test labels \n",
    "    print(f\"Val loss: {test_loss/len(test_loader)}\") # print average test loss \n",
    "    weights = [2,1,1]\n",
    "    acc = accuracy_score(test_labels, test_preds)\n",
    "    pre = graded_precision(test_labels, test_preds, weights)\n",
    "    rec = graded_recall(test_labels, test_preds, weights)\n",
    "    f1 = graded_f1(pre, rec)\n",
    "    kappa = cohen_kappa_score(test_labels, test_preds)\n",
    "    val_acc.append(acc)\n",
    "    val_gp.append(prec)\n",
    "    val_gr.append(rec)\n",
    "    val_f1.append(f1)\n",
    "    val_kp.append(kappa)\n",
    "    print(f\"Val accuracy: {acc}\") \n",
    "    print(f\"Val precision: {pre}\") \n",
    "    print(f\"Val recall: {rec}\") \n",
    "    print(f\"Val f1 score: {f1}\") \n",
    "    print(f\"Val Kappa: {kappa}\") \n",
    "    \n",
    "    # Test model\n",
    "    model.eval() # set model to eval mode\n",
    "    test_loss = 0.0  # initialize test loss\n",
    "    with torch.no_grad(): # no gradient computation\n",
    "        for batch in test_loader:\n",
    "            input_ids, attention_mask, labels = batch # get batch data\n",
    "            input_ids = input_ids.to(device) # move input ids to device\n",
    "            attention_mask = attention_mask.to(device) # move attention mask to device\n",
    "            labels = labels.to(device) # move labels to device\n",
    "            outputs = model(input_ids, attention_mask=attention_mask) # forward pass\n",
    "            loss = criterion(outputs.logits, labels) # compute loss\n",
    "            preds = torch.argmax(outputs.logits, dim=1) # get predictions\n",
    "            test_loss += loss.item() # accumulate test loss \n",
    "            test_preds.extend(preds.cpu().tolist()) # store test predictions \n",
    "            test_labels.extend(labels.cpu().tolist()) # store test labels \n",
    "    print(f\"Test loss: {test_loss/len(test_loader)}\") # print average test loss \n",
    "    weights = [2,1,1]\n",
    "    CM(test_labels, test_preds, times)\n",
    "    acc = accuracy_score(test_labels, test_preds)\n",
    "    pre = graded_precision(test_labels, test_preds, weights)\n",
    "    rec = graded_recall(test_labels, test_preds, weights)\n",
    "    f1 = graded_f1(pre, rec)\n",
    "    kappa = cohen_kappa_score(test_labels, test_preds)\n",
    "    tes_acc.append(acc)\n",
    "    tes_gp.append(prec)\n",
    "    tes_gr.append(rec)\n",
    "    tes_f1.append(f1)\n",
    "    tes_kp.append(kappa)\n",
    "    print(f\"Test accuracy: {acc}\") \n",
    "    print(f\"Test precision: {pre}\") \n",
    "    print(f\"Test recall: {rec}\") \n",
    "    print(f\"Test f1 score: {f1}\") \n",
    "    print(f\"Test Kappa: {kappa}\") \n",
    "    \n",
    "    times = times + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83625817",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/ROG/OneDrive/桌面/FYP/Model/MentalBERT.txt\", \"w\") as f:\n",
    "    f.write(\"val_acc: \")\n",
    "    for item in val_acc:\n",
    "        f.write(str(item))\n",
    "        if val_acc.index(item) == len(val_acc) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"val_gp: \")\n",
    "    for item in val_gp:\n",
    "        f.write(str(item))\n",
    "        if val_gp.index(item) == len(val_acc) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"val_gr: \")\n",
    "    for item in val_gr:\n",
    "        f.write(str(item))\n",
    "        if val_gr.index(item) == len(val_acc) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")  \n",
    "        \n",
    "    f.write(\"val_f1: \")\n",
    "    for item in val_f1:\n",
    "        f.write(str(item))\n",
    "        if val_f1.index(item) == len(val_acc) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")  \n",
    "    \n",
    "    f.write(\"val_kp: \")\n",
    "    for item in val_kp:\n",
    "        f.write(str(item))\n",
    "        if val_kp.index(item) == len(val_acc) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")   \n",
    "    \n",
    "    f.write(\"tes_acc: \")\n",
    "    for item in tes_acc:\n",
    "        f.write(str(item))\n",
    "        if tes_acc.index(item) == len(val_acc) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")  \n",
    "        \n",
    "    f.write(\"tes_gp: \")\n",
    "    for item in tes_gp:\n",
    "        f.write(str(item))\n",
    "        if tes_gp.index(item) == len(val_acc) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")  \n",
    "        \n",
    "    f.write(\"tes_gr: \")\n",
    "    for item in tes_gr:\n",
    "        f.write(str(item))\n",
    "        if tes_gr.index(item) == len(val_acc) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")  \n",
    "            \n",
    "    f.write(\"tes_f1: \")\n",
    "    for item in tes_f1:\n",
    "        f.write(str(item))\n",
    "        if tes_f1.index(item) == len(val_acc) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")  \n",
    "            \n",
    "    f.write(\"tes_kp: \")\n",
    "    for item in tes_kp:\n",
    "        f.write(str(item))\n",
    "        if tes_kp.index(item) == len(val_acc) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"train_time: \")\n",
    "    for item in train_time:\n",
    "        f.write(str(item))\n",
    "        if train_time.index(item) == len(train_time) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"average_results: \")\n",
    "    for item in avg_results:\n",
    "        f.write(str(item))\n",
    "        if avg_results.index(item) == len(avg_results) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f31594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
