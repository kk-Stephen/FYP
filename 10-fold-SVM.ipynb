{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bb9ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'C:/Users/ROG/OneDrive/桌面/FYP/Dataset/Train_data/train_data_after_washing.csv'\n",
    "test_dir = 'C:/Users/ROG/OneDrive/桌面/FYP/Dataset/Test_data/test_data_after_washing.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2620bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from tensorflow.keras.models import Model\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score, cohen_kappa_score, roc_curve, auc, make_scorer, accuracy_score, f1_score \n",
    "tf.get_logger().setLevel('ERROR') # return ERROR messages, ignore others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed1de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "data = pd.read_csv(train_dir)\n",
    "data = pd.DataFrame(data)\n",
    "test_data = pd.read_csv(test_dir)\n",
    "test_data = pd.DataFrame(test_data)\n",
    "train_data = pd.DataFrame()\n",
    "val_data = pd.DataFrame()\n",
    "data = data[[\"review\",\"rating\"]]\n",
    "test_data = test_data[[\"review\",\"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c7db998",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['labels'] = data['rating'].map({1 : 0,\n",
    "                                     2 : 0,\n",
    "                                     3 : 0,\n",
    "                                     4 : 0,\n",
    "                                     5 : 1,\n",
    "                                     6 : 1,\n",
    "                                     7 : 1,\n",
    "                                     8 : 1,\n",
    "                                     9 : 2,\n",
    "                                     10 : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14b86840",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['labels'] = test_data['rating'].map({1 : 0,\n",
    "                                               2 : 0,\n",
    "                                               3 : 0,\n",
    "                                               4 : 0,\n",
    "                                               5 : 1,\n",
    "                                               6 : 1,\n",
    "                                               7 : 1,\n",
    "                                               8 : 1,\n",
    "                                               9 : 2,\n",
    "                                               10 : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbcbcdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract data\n",
    "data = data[[\"review\",\"labels\"]]\n",
    "y = data[\"labels\"].to_numpy()\n",
    "#data = encode_one_hot(data)\n",
    "test_data = test_data[[\"review\",\"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80f36947",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"review\"].to_numpy()\n",
    "#Y = data[[0,1,2]].to_numpy\n",
    "test_X = test_data[\"review\"].to_numpy()\n",
    "test_y = test_data[\"labels\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d90d5cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    wn = nltk.WordNetLemmatizer()\n",
    "    stopword = nltk.corpus.stopwords.words('english') #remove useless words\n",
    "    tokens = nltk.word_tokenize(text) #Tokenizers divide strings into lists of substrings\n",
    "    lower = [word.lower() for word in tokens] #remove uppercase\n",
    "    no_stopwords = [word for word in lower if word not in stopword]\n",
    "    no_alpha = [word for word in no_stopwords if word.isalpha()]\n",
    "    lemm_text = [wn.lemmatize(word) for word in no_alpha]\n",
    "    clean_text = lemm_text\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1c19995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def vectorize(data,tfidf_vect_fit):\n",
    "    X_tfidf = tfidf_vect_fit.transform(data) #Transform doc to matrix \n",
    "    words = tfidf_vect_fit.get_feature_names_out() #Get features names\n",
    "    X_tfidf_df = pd.DataFrame(X_tfidf.toarray())\n",
    "    X_tfidf_df.columns = words\n",
    "    return(X_tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b74da05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graded_precision(y_true, y_pred, weights):\n",
    "    precision_0 = precision_score(y_true, y_pred, labels=[0], average='macro')\n",
    "    precision_1 = precision_score(y_true, y_pred, labels=[1], average='macro')\n",
    "    precision_2 = precision_score(y_true, y_pred, labels=[2], average='macro')\n",
    "    gp = ( weights[0] * precision_0 + weights[1] * precision_1 + weights[2] * precision_2 ) / ( weights[0] + weights[1] + weights[2] )\n",
    "    return gp\n",
    "def graded_recall(y_true, y_pred, weights):\n",
    "    recall_0 = recall_score(y_true, y_pred, labels=[0], average='macro')\n",
    "    recall_1 = recall_score(y_true, y_pred, labels=[1], average='macro')\n",
    "    recall_2 = recall_score(y_true, y_pred, labels=[2], average='macro')\n",
    "    gr = ( weights[0] * recall_0 + weights[1] * recall_1 + weights[2] * recall_2 ) / ( weights[0] + weights[1] + weights[2] )\n",
    "    return gr\n",
    "def graded_f1(precision, recall):\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44138ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(x_train, y_train, times):\n",
    "    t0 = time.time()\n",
    "    tfidf_vect = TfidfVectorizer(analyzer=clean, max_features=6000)\n",
    "    tfidf_vect_fit=tfidf_vect.fit(x_train)\n",
    "    x_train = vectorize(x_train,tfidf_vect_fit)\n",
    "    classifier_linear = OneVsOneClassifier(svm.SVC(kernel='rbf', class_weight='balanced'))\n",
    "    classifier_linear.fit(x_train,y_train)\n",
    "    t1 = time.time()\n",
    "    time_train = t1-t0\n",
    "    return (tfidf_vect_fit, classifier_linear,time_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a46e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_testing(encoder, model, X, y, times, val):\n",
    "    times = str(times)\n",
    "    #generate y_true and prediction results\n",
    "    y_true = y\n",
    "    X = vectorize(X, encoder)\n",
    "    pred = model.predict(X)\n",
    "    \n",
    "    #different metrics\n",
    "    acc = accuracy_score(y_true, pred)\n",
    "    weights = [2, 1, 1]\n",
    "    prec = graded_precision(y_true, pred, weights)\n",
    "    rec = graded_recall(y_true, pred, weights)\n",
    "    f1 = graded_f1(prec, rec)\n",
    "    kappa = cohen_kappa_score(y_true, pred)\n",
    "    \n",
    "    #CM\n",
    "    if val == False:\n",
    "        con_mat = confusion_matrix(y, pred)\n",
    "        con_mat_norm = con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis]     # 归一化\n",
    "        con_mat_norm = np.around(con_mat_norm, decimals=2)\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(con_mat_norm, annot=True, cmap='Blues')\n",
    "        plt.ylim(0, 3)\n",
    "        plt.xlabel('Predicted labels')\n",
    "        plt.ylabel('True labels')\n",
    "        #save CM\n",
    "        file_name='W+S_' + times\n",
    "        path ='C:/Users/ROG/OneDrive/桌面/FYP/Model/'+ file_name \n",
    "        os.mkdir(path)\n",
    "        plt.savefig(fname=path + '/CM.png', dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    return (acc, prec, rec, f1, kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b26af695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#10-fold\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "val_acc = []\n",
    "val_gp = []\n",
    "val_gr = []\n",
    "val_f1 = []\n",
    "val_kp = []\n",
    "tes_acc = []\n",
    "tes_gp = []\n",
    "tes_gr = []\n",
    "tes_f1 = []\n",
    "tes_kp = []\n",
    "train_time = []\n",
    "times = 0\n",
    "\n",
    "for train_index, val_index in skf.split(X, y):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    #X_train = bert_layer_model.predict(X_train)\n",
    "    #X_val = bert_layer_model.predict(X_val)\n",
    "    \n",
    "    encoder, model, time_train = model_training(X_train, y_train, times)\n",
    "    train_time.append(time_train)\n",
    "    \n",
    "    val = True\n",
    "    acc, prec, rec, f1, kappa = model_testing(encoder, model, X_val, y_val, times, val)\n",
    "    val_acc.append(acc)\n",
    "    val_gp.append(prec)\n",
    "    val_gr.append(rec)\n",
    "    val_f1.append(f1)\n",
    "    val_kp.append(kappa)\n",
    "        \n",
    "    val = False\n",
    "    #test_X = bert_layer_model.predict(test_X)\n",
    "    acc, prec, rec, f1, kappa = model_testing(encoder, model, test_X, test_y, times, val)\n",
    "    tes_acc.append(acc)\n",
    "    tes_gp.append(prec)\n",
    "    tes_gr.append(rec)\n",
    "    tes_f1.append(f1)\n",
    "    tes_kp.append(kappa)\n",
    "    times = times + 1\n",
    "    print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "534a4a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrics_list = [val_acc, val_gp, val_gr, val_f1, val_kp, tes_acc, tes_gp, tes_gr, tes_f1, tes_kp, train_time]\n",
    "avg_results = []\n",
    "for matric in matrics_list:\n",
    "    total = 0\n",
    "    for item in matric:\n",
    "        total = total + item\n",
    "    avg_results.append(total/len(matric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64290b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/ROG/OneDrive/桌面/FYP/Model/Word_SVM.txt\", \"w\") as f:\n",
    "    f.write(\"val_acc: \")\n",
    "    for item in val_acc:\n",
    "        f.write(str(item))\n",
    "        if val_acc.index(item) == len(val_acc) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"val_gp: \")\n",
    "    for item in val_gp:\n",
    "        f.write(str(item))\n",
    "        if val_gp.index(item) == len(val_acc) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"val_gr: \")\n",
    "    for item in val_gr:\n",
    "        f.write(str(item))\n",
    "        if val_gr.index(item) == len(val_acc) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")  \n",
    "        \n",
    "    f.write(\"val_f1: \")\n",
    "    for item in val_f1:\n",
    "        f.write(str(item))\n",
    "        if val_f1.index(item) == len(val_acc) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")  \n",
    "    \n",
    "    f.write(\"val_kp: \")\n",
    "    for item in val_kp:\n",
    "        f.write(str(item))\n",
    "        if val_kp.index(item) == len(val_acc) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")   \n",
    "    \n",
    "    f.write(\"tes_acc: \")\n",
    "    for item in tes_acc:\n",
    "        f.write(str(item))\n",
    "        if tes_acc.index(item) == len(val_acc) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")  \n",
    "        \n",
    "    f.write(\"tes_gp: \")\n",
    "    for item in tes_gp:\n",
    "        f.write(str(item))\n",
    "        if tes_gp.index(item) == len(val_acc) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")  \n",
    "        \n",
    "    f.write(\"tes_gr: \")\n",
    "    for item in tes_gr:\n",
    "        f.write(str(item))\n",
    "        if tes_gr.index(item) == len(val_acc) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")  \n",
    "            \n",
    "    f.write(\"tes_f1: \")\n",
    "    for item in tes_f1:\n",
    "        f.write(str(item))\n",
    "        if tes_f1.index(item) == len(val_acc) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")  \n",
    "            \n",
    "    f.write(\"tes_kp: \")\n",
    "    for item in tes_kp:\n",
    "        f.write(str(item))\n",
    "        if tes_kp.index(item) == len(val_acc) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"train_time: \")\n",
    "    for item in train_time:\n",
    "        f.write(str(item))\n",
    "        if train_time.index(item) == len(train_time) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"average_results: \")\n",
    "    for item in avg_results:\n",
    "        f.write(str(item))\n",
    "        if avg_results.index(item) == len(avg_results) - 1: # Check if last item\n",
    "            f.write(';')\n",
    "        else:\n",
    "            f.write(', ')\n",
    "    f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
